{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b921afd-8d8c-41ca-bcc5-557e2f3dfd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ramya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ramya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ramya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ramya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7444e1e-5469-4443-9cee-d616e2509c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramya\\AppData\\Local\\Temp\\ipykernel_5672\\1136658433.py:2: DtypeWarning: Columns (10,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"D:/Bookify.com/New folder/Database/database/cleaned_datasets/processed_reviews.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>asin</th>\n",
       "      <th>book_name</th>\n",
       "      <th>author</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>...</th>\n",
       "      <th>verified</th>\n",
       "      <th>helpful</th>\n",
       "      <th>combined_review</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tokens</th>\n",
       "      <th>joined</th>\n",
       "      <th>w2v_vector</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48235e132322f1f1d38273eb33bde48f</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>Entertaining But Average Jace Rankin may be sh...</td>\n",
       "      <td>entertaining but average jace rankin may be sh...</td>\n",
       "      <td>entertaining average jace rankin may short hes...</td>\n",
       "      <td>entertaining average jace rankin may short he ...</td>\n",
       "      <td>['entertaining', 'average', 'jace', 'rankin', ...</td>\n",
       "      <td>entertaining average jace rankin may short he ...</td>\n",
       "      <td>[-0.36792505 -0.9909726   0.27137458  0.034692...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ef97bbe96ff2ffe7dfb0852e39a0e1ea</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-10-08</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Terrific menage scenes! Great short read.  I d...</td>\n",
       "      <td>terrific menage scenes great short read i didn...</td>\n",
       "      <td>terrific menage scenes great short read didnt ...</td>\n",
       "      <td>terrific menage scene great short read didnt w...</td>\n",
       "      <td>['terrific', 'menage', 'scene', 'great', 'shor...</td>\n",
       "      <td>terrific menage scene great short read didnt w...</td>\n",
       "      <td>[-0.5433881  -1.7709152   0.67714506 -0.005419...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ffa408e5333fda43220110b396f469d9</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Snapdragon Alley I'll start by saying this is ...</td>\n",
       "      <td>snapdragon alley ill start by saying this is t...</td>\n",
       "      <td>snapdragon alley ill start saying first four b...</td>\n",
       "      <td>snapdragon alley ill start saying first four b...</td>\n",
       "      <td>['snapdragon', 'alley', 'ill', 'start', 'sayin...</td>\n",
       "      <td>snapdragon alley ill start saying first four b...</td>\n",
       "      <td>[-0.26081926 -1.2878057   0.27687296  0.119117...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d5b5ad9a44016bc335af15c715efa85d</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-07-05</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>very light murder cozy Aggie is Angela Lansbur...</td>\n",
       "      <td>very light murder cozy aggie is angela lansbur...</td>\n",
       "      <td>light murder cozy aggie angela lansbury carrie...</td>\n",
       "      <td>light murder cozy aggie angela lansbury carry ...</td>\n",
       "      <td>['light', 'murder', 'cozy', 'aggie', 'angela',...</td>\n",
       "      <td>light murder cozy aggie angela lansbury carry ...</td>\n",
       "      <td>[-0.474576   -1.2394472   0.23362859 -0.098878...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6f54882f555c3a31bf0bc5a2d007e1e8</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Book I did not expect this type of book to be ...</td>\n",
       "      <td>book i did not expect this type of book to be ...</td>\n",
       "      <td>book expect type book library pleased find pri...</td>\n",
       "      <td>book expect type book library pleased find pri...</td>\n",
       "      <td>['book', 'expect', 'type', 'book', 'library', ...</td>\n",
       "      <td>book expect type book library pleased find pri...</td>\n",
       "      <td>[ 0.35064948 -1.2930781   0.01877313  0.345010...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79462</th>\n",
       "      <td>0bbafa54ee3f1f8485989d717f8e0285</td>\n",
       "      <td>CustomerReviews</td>\n",
       "      <td>1492646318</td>\n",
       "      <td>How to Catch an Elf</td>\n",
       "      <td>Adam Wallace</td>\n",
       "      <td>Carol Mccoy</td>\n",
       "      <td>A cute Christmas book for STEM</td>\n",
       "      <td>Definitely a cute read aloud book to get kids ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>A cute Christmas book for STEM Definitely a cu...</td>\n",
       "      <td>a cute christmas book for stem definitely a cu...</td>\n",
       "      <td>cute christmas book stem definitely cute read ...</td>\n",
       "      <td>cute christmas book stem definitely cute read ...</td>\n",
       "      <td>['cute', 'christmas', 'book', 'stem', 'definit...</td>\n",
       "      <td>cute christmas book stem definitely cute read ...</td>\n",
       "      <td>[-0.16936101 -0.6945811   0.3211885  -0.084966...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79463</th>\n",
       "      <td>7898c8d5febb0343f769a569dbd086a8</td>\n",
       "      <td>CustomerReviews</td>\n",
       "      <td>1501161938</td>\n",
       "      <td>The Seven Husbands of Evelyn Hugo: A Novel</td>\n",
       "      <td>Morgan Housel</td>\n",
       "      <td>Chelscey</td>\n",
       "      <td>Hollywood hasn't changed much</td>\n",
       "      <td>Starting at the young age of fourteen and endi...</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hollywood hasn't changed much Starting at the ...</td>\n",
       "      <td>hollywood hasnt changed much starting at the y...</td>\n",
       "      <td>hollywood hasnt changed much starting young ag...</td>\n",
       "      <td>hollywood hasnt changed much starting young ag...</td>\n",
       "      <td>['hollywood', 'hasnt', 'changed', 'much', 'sta...</td>\n",
       "      <td>hollywood hasnt changed much starting young ag...</td>\n",
       "      <td>[-2.37564310e-01 -1.08791089e+00  3.39659393e-...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79464</th>\n",
       "      <td>ac52669eb95d9637b39a39d44bd48fa9</td>\n",
       "      <td>CustomerReviews</td>\n",
       "      <td>385534264</td>\n",
       "      <td>The Wager: A Tale of Shipwreck, Mutiny and Murder</td>\n",
       "      <td>David Grann</td>\n",
       "      <td>bayrider</td>\n",
       "      <td>Very Good Narrative Nonfiction</td>\n",
       "      <td>I really liked this work of narrative nonficti...</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Good Narrative Nonfiction I really liked ...</td>\n",
       "      <td>very good narrative nonfiction i really liked ...</td>\n",
       "      <td>good narrative nonfiction really liked work na...</td>\n",
       "      <td>good narrative nonfiction really liked work na...</td>\n",
       "      <td>['good', 'narrative', 'nonfiction', 'really', ...</td>\n",
       "      <td>good narrative nonfiction really liked work na...</td>\n",
       "      <td>[-0.38606504 -1.5109701   0.36016968  0.082981...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79465</th>\n",
       "      <td>3a90ac5bf4884a7e047b1c8cf2bfd8dd</td>\n",
       "      <td>CustomerReviews</td>\n",
       "      <td>B0B6XFT4RH</td>\n",
       "      <td>Interesting Facts For Curious Minds: 1572 Rand...</td>\n",
       "      <td>Jordan Moore</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>great book!!!!</td>\n",
       "      <td>Amazing facts!!!! I couldn’t put it down. This...</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>great book!!!! Amazing facts!!!! I couldn’t pu...</td>\n",
       "      <td>great book amazing facts i couldnt put it down...</td>\n",
       "      <td>great book amazing facts couldnt put great par...</td>\n",
       "      <td>great book amazing fact couldnt put great part...</td>\n",
       "      <td>['great', 'book', 'amazing', 'fact', 'couldnt'...</td>\n",
       "      <td>great book amazing fact couldnt put great part...</td>\n",
       "      <td>[-0.18140039 -1.5045485   0.5730947  -0.226274...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79466</th>\n",
       "      <td>172a7d70bd681609528613c7d164a919</td>\n",
       "      <td>CustomerReviews</td>\n",
       "      <td>1728213746</td>\n",
       "      <td>I Love You Like No Otter: A Funny and Sweet An...</td>\n",
       "      <td>Rose Rossner</td>\n",
       "      <td>Jeanette F. Reeder</td>\n",
       "      <td>Great for little ones!</td>\n",
       "      <td>Easy to see, and cute pictures to keep little ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-10-25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great for little ones! Easy to see, and cute p...</td>\n",
       "      <td>great for little ones easy to see and cute pic...</td>\n",
       "      <td>great little ones easy see cute pictures keep ...</td>\n",
       "      <td>great little one easy see cute picture keep li...</td>\n",
       "      <td>['great', 'little', 'one', 'easy', 'see', 'cut...</td>\n",
       "      <td>great little one easy see cute picture keep li...</td>\n",
       "      <td>[-0.2547107  -1.5191662   0.6677059  -0.097126...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79467 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              review_id         platform        asin  \\\n",
       "0      48235e132322f1f1d38273eb33bde48f           Amazon  B0033UV8HI   \n",
       "1      ef97bbe96ff2ffe7dfb0852e39a0e1ea           Amazon  B002HJV4DE   \n",
       "2      ffa408e5333fda43220110b396f469d9           Amazon  B002ZG96I4   \n",
       "3      d5b5ad9a44016bc335af15c715efa85d           Amazon  B002QHWOEU   \n",
       "4      6f54882f555c3a31bf0bc5a2d007e1e8           Amazon  B001A06VJ8   \n",
       "...                                 ...              ...         ...   \n",
       "79462  0bbafa54ee3f1f8485989d717f8e0285  CustomerReviews  1492646318   \n",
       "79463  7898c8d5febb0343f769a569dbd086a8  CustomerReviews  1501161938   \n",
       "79464  ac52669eb95d9637b39a39d44bd48fa9  CustomerReviews   385534264   \n",
       "79465  3a90ac5bf4884a7e047b1c8cf2bfd8dd  CustomerReviews  B0B6XFT4RH   \n",
       "79466  172a7d70bd681609528613c7d164a919  CustomerReviews  1728213746   \n",
       "\n",
       "                                               book_name         author  \\\n",
       "0                                          Not Available  Not Available   \n",
       "1                                          Not Available  Not Available   \n",
       "2                                          Not Available  Not Available   \n",
       "3                                          Not Available  Not Available   \n",
       "4                                          Not Available  Not Available   \n",
       "...                                                  ...            ...   \n",
       "79462                                How to Catch an Elf   Adam Wallace   \n",
       "79463         The Seven Husbands of Evelyn Hugo: A Novel  Morgan Housel   \n",
       "79464  The Wager: A Tale of Shipwreck, Mutiny and Murder    David Grann   \n",
       "79465  Interesting Facts For Curious Minds: 1572 Rand...   Jordan Moore   \n",
       "79466  I Love You Like No Otter: A Funny and Sweet An...   Rose Rossner   \n",
       "\n",
       "            reviewer_name                    review_title  \\\n",
       "0                  Ridley        Entertaining But Average   \n",
       "1            Holly Butler         Terrific menage scenes!   \n",
       "2                 Merissa                Snapdragon Alley   \n",
       "3              Cleargrace          very light murder cozy   \n",
       "4                Rjostler                            Book   \n",
       "...                   ...                             ...   \n",
       "79462         Carol Mccoy  A cute Christmas book for STEM   \n",
       "79463            Chelscey   Hollywood hasn't changed much   \n",
       "79464            bayrider  Very Good Narrative Nonfiction   \n",
       "79465     Amazon Customer                  great book!!!!   \n",
       "79466  Jeanette F. Reeder          Great for little ones!   \n",
       "\n",
       "                                             review_text  rating review_date  \\\n",
       "0      Jace Rankin may be short, but he's nothing to ...       3  2010-09-02   \n",
       "1      Great short read.  I didn't want to put it dow...       5  2013-10-08   \n",
       "2      I'll start by saying this is the first of four...       3  2014-04-11   \n",
       "3      Aggie is Angela Lansbury who carries pocketboo...       3  2014-07-05   \n",
       "4      I did not expect this type of book to be in li...       4  2012-12-31   \n",
       "...                                                  ...     ...         ...   \n",
       "79462  Definitely a cute read aloud book to get kids ...       5  2023-09-04   \n",
       "79463  Starting at the young age of fourteen and endi...       5  2022-04-25   \n",
       "79464  I really liked this work of narrative nonficti...       4  2023-09-09   \n",
       "79465  Amazing facts!!!! I couldn’t put it down. This...       5  2023-10-01   \n",
       "79466  Easy to see, and cute pictures to keep little ...       5  2023-10-25   \n",
       "\n",
       "       ... verified  helpful  \\\n",
       "0      ...    False  [8, 10]   \n",
       "1      ...    False   [1, 1]   \n",
       "2      ...    False   [0, 0]   \n",
       "3      ...    False   [1, 3]   \n",
       "4      ...    False   [0, 1]   \n",
       "...    ...      ...      ...   \n",
       "79462  ...      1.0        0   \n",
       "79463  ...      1.0        0   \n",
       "79464  ...      1.0        0   \n",
       "79465  ...      1.0        0   \n",
       "79466  ...      1.0        0   \n",
       "\n",
       "                                         combined_review  \\\n",
       "0      Entertaining But Average Jace Rankin may be sh...   \n",
       "1      Terrific menage scenes! Great short read.  I d...   \n",
       "2      Snapdragon Alley I'll start by saying this is ...   \n",
       "3      very light murder cozy Aggie is Angela Lansbur...   \n",
       "4      Book I did not expect this type of book to be ...   \n",
       "...                                                  ...   \n",
       "79462  A cute Christmas book for STEM Definitely a cu...   \n",
       "79463  Hollywood hasn't changed much Starting at the ...   \n",
       "79464  Very Good Narrative Nonfiction I really liked ...   \n",
       "79465  great book!!!! Amazing facts!!!! I couldn’t pu...   \n",
       "79466  Great for little ones! Easy to see, and cute p...   \n",
       "\n",
       "                                                 cleaned  \\\n",
       "0      entertaining but average jace rankin may be sh...   \n",
       "1      terrific menage scenes great short read i didn...   \n",
       "2      snapdragon alley ill start by saying this is t...   \n",
       "3      very light murder cozy aggie is angela lansbur...   \n",
       "4      book i did not expect this type of book to be ...   \n",
       "...                                                  ...   \n",
       "79462  a cute christmas book for stem definitely a cu...   \n",
       "79463  hollywood hasnt changed much starting at the y...   \n",
       "79464  very good narrative nonfiction i really liked ...   \n",
       "79465  great book amazing facts i couldnt put it down...   \n",
       "79466  great for little ones easy to see and cute pic...   \n",
       "\n",
       "                                            no_stopwords  \\\n",
       "0      entertaining average jace rankin may short hes...   \n",
       "1      terrific menage scenes great short read didnt ...   \n",
       "2      snapdragon alley ill start saying first four b...   \n",
       "3      light murder cozy aggie angela lansbury carrie...   \n",
       "4      book expect type book library pleased find pri...   \n",
       "...                                                  ...   \n",
       "79462  cute christmas book stem definitely cute read ...   \n",
       "79463  hollywood hasnt changed much starting young ag...   \n",
       "79464  good narrative nonfiction really liked work na...   \n",
       "79465  great book amazing facts couldnt put great par...   \n",
       "79466  great little ones easy see cute pictures keep ...   \n",
       "\n",
       "                                              lemmatized  \\\n",
       "0      entertaining average jace rankin may short he ...   \n",
       "1      terrific menage scene great short read didnt w...   \n",
       "2      snapdragon alley ill start saying first four b...   \n",
       "3      light murder cozy aggie angela lansbury carry ...   \n",
       "4      book expect type book library pleased find pri...   \n",
       "...                                                  ...   \n",
       "79462  cute christmas book stem definitely cute read ...   \n",
       "79463  hollywood hasnt changed much starting young ag...   \n",
       "79464  good narrative nonfiction really liked work na...   \n",
       "79465  great book amazing fact couldnt put great part...   \n",
       "79466  great little one easy see cute picture keep li...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['entertaining', 'average', 'jace', 'rankin', ...   \n",
       "1      ['terrific', 'menage', 'scene', 'great', 'shor...   \n",
       "2      ['snapdragon', 'alley', 'ill', 'start', 'sayin...   \n",
       "3      ['light', 'murder', 'cozy', 'aggie', 'angela',...   \n",
       "4      ['book', 'expect', 'type', 'book', 'library', ...   \n",
       "...                                                  ...   \n",
       "79462  ['cute', 'christmas', 'book', 'stem', 'definit...   \n",
       "79463  ['hollywood', 'hasnt', 'changed', 'much', 'sta...   \n",
       "79464  ['good', 'narrative', 'nonfiction', 'really', ...   \n",
       "79465  ['great', 'book', 'amazing', 'fact', 'couldnt'...   \n",
       "79466  ['great', 'little', 'one', 'easy', 'see', 'cut...   \n",
       "\n",
       "                                                  joined  \\\n",
       "0      entertaining average jace rankin may short he ...   \n",
       "1      terrific menage scene great short read didnt w...   \n",
       "2      snapdragon alley ill start saying first four b...   \n",
       "3      light murder cozy aggie angela lansbury carry ...   \n",
       "4      book expect type book library pleased find pri...   \n",
       "...                                                  ...   \n",
       "79462  cute christmas book stem definitely cute read ...   \n",
       "79463  hollywood hasnt changed much starting young ag...   \n",
       "79464  good narrative nonfiction really liked work na...   \n",
       "79465  great book amazing fact couldnt put great part...   \n",
       "79466  great little one easy see cute picture keep li...   \n",
       "\n",
       "                                              w2v_vector sentiment  \n",
       "0      [-0.36792505 -0.9909726   0.27137458  0.034692...   neutral  \n",
       "1      [-0.5433881  -1.7709152   0.67714506 -0.005419...  positive  \n",
       "2      [-0.26081926 -1.2878057   0.27687296  0.119117...   neutral  \n",
       "3      [-0.474576   -1.2394472   0.23362859 -0.098878...   neutral  \n",
       "4      [ 0.35064948 -1.2930781   0.01877313  0.345010...  positive  \n",
       "...                                                  ...       ...  \n",
       "79462  [-0.16936101 -0.6945811   0.3211885  -0.084966...  positive  \n",
       "79463  [-2.37564310e-01 -1.08791089e+00  3.39659393e-...  positive  \n",
       "79464  [-0.38606504 -1.5109701   0.36016968  0.082981...  positive  \n",
       "79465  [-0.18140039 -1.5045485   0.5730947  -0.226274...  positive  \n",
       "79466  [-0.2547107  -1.5191662   0.6677059  -0.097126...  positive  \n",
       "\n",
       "[79467 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"D:/Bookify.com/New folder/Database/database/cleaned_datasets/processed_reviews.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b184bf-de9c-4d56-b1cd-b0cb1f57052e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF\n",
      "TF-IDF Feature Matrix:\n",
      "Shape: (79467, 1000)\n",
      "Sparsity: 94.99%\n"
     ]
    }
   ],
   "source": [
    "# PART 1: TF-IDF Vectorization \n",
    "\n",
    "print(\"\\nTF-IDF\")\n",
    "\n",
    "# Example configuration\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=1000, min_df=5, max_df=0.8)\n",
    "X_tfidf = vectorizer.fit_transform(df['joined'])\n",
    "\n",
    "print(\"TF-IDF Feature Matrix:\")\n",
    "print(\"Shape:\", X_tfidf.shape)\n",
    "print(\"Sparsity: {:.2f}%\".format(100.0 * (1.0 - X_tfidf.count_nonzero() / (X_tfidf.shape[0] * X_tfidf.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30fe65f-f91a-49cc-bf8b-db2bbb626100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# Example: TF-IDF features used\n",
    "X = X_tfidf  # or use review_vectors for Word2Vec\n",
    "y = df['sentiment']  # Make sure this is encoded (e.g., LabelEncoder)\n",
    "\n",
    "# Label encode sentiments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "428b952a-aee8-4155-b8ca-d29cef42d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = logistic_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ee5ca-74c6-4a20-be98-ccfee038c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = LinearSVC()\n",
    "calibrated_svm = CalibratedClassifierCV(svm_model)\n",
    "calibrated_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = calibrated_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c0364-9dda-41da-b0f9-fa76ac2dfb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ff656-4a4e-4c77-a41e-c688652a8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_pred):\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=le.classes_))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f3cb0-5733-444c-bb83-c8b85a77bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"Logistic Regression\", y_test, y_pred_log)\n",
    "evaluate_model(\"SVM\", y_test, y_pred_svm)\n",
    "evaluate_model(\"Random Forest\", y_test, y_pred_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
