{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a432d50-edf7-48a3-84ac-64905bc6b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Collaborative Filtering ---\n",
      "CF RMSE: 3.4933\n",
      "CF Avg Precision@10: 0.1972\n",
      "CF Avg Recall@10: 0.1780\n",
      "\n",
      "--- Content-Based Filtering ---\n",
      "CBF Avg Precision@10: 0.0000\n",
      "CBF Avg Recall@10: 0.0000\n",
      "CBF Avg Diversity@10: 0.6727\n",
      "\n",
      "--- Hybrid Recommendation ---\n",
      "Hybrid recommendations for user 276725 based on 'black water':\n",
      "- potshot\n",
      "- god save the child\n",
      "- all our yesterdays large print\n",
      "- suspicion of deceit\n",
      "- sudden mischief spenser mysteries hardcover\n",
      "- a tally of types with additions by several hands  and with a new introduction by mike parker\n",
      "- tithe\n",
      "- the broken hearts club\n",
      "- franklin delano roosevelt champion of freedom\n",
      "- the great pretender\n",
      "- the little prince\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import html\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, pairwise\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# -------------------- A. Evaluation Metrics --------------------\n",
    "\n",
    "def calculate_rmse(actual_ratings, predicted_ratings):\n",
    "    return np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "\n",
    "def calculate_rmse_surprise(predictions):\n",
    "    return accuracy.rmse(predictions, verbose=False)\n",
    "\n",
    "def precision_at_k(actual, predicted, k=10, threshold=4):\n",
    "    actual_set = {item: rating for item, rating in actual.items() if rating >= threshold}\n",
    "    predicted_set = set(predicted[:k])\n",
    "    relevant_items = actual_set.keys() & predicted_set\n",
    "    precision = len(relevant_items) / k if predicted else 0\n",
    "    return precision\n",
    "\n",
    "def recall_at_k(actual, predicted, k=10, threshold=4):\n",
    "    actual_set = {item: rating for item, rating in actual.items() if rating >= threshold}\n",
    "    predicted_set = set(predicted[:k])\n",
    "    relevant_items = actual_set.keys() & predicted_set\n",
    "    recall = len(relevant_items) / len(actual_set) if actual_set else 0\n",
    "    return recall\n",
    "\n",
    "def precision_recall_at_k_surprise(predictions, k=10, threshold=4):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions, recalls = {}, {}\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        n_rel_and_rec_k = sum(((est >= threshold) and (true_r >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k else 0\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel else 0\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "# -------------------- B. Collaborative Filtering --------------------\n",
    "\n",
    "def load_and_prepare_cf_data(file=\"D:/ratings_cleaned.csv\", rating_scale=(1, 10), test_size=0.2):\n",
    "    ratings = pd.read_csv(file)\n",
    "    reader = Reader(rating_scale=rating_scale)\n",
    "    data = Dataset.load_from_df(ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "    return data, *train_test_split(data, test_size=test_size)\n",
    "\n",
    "def train_svd_model(trainset, n_factors=100):\n",
    "    algo = SVD(n_factors=n_factors, random_state=42)\n",
    "    algo.fit(trainset)\n",
    "    return algo\n",
    "\n",
    "def evaluate_cf_model(algo, testset, k=10, threshold=4):\n",
    "    predictions = algo.test(testset)\n",
    "    rmse = calculate_rmse_surprise(predictions)\n",
    "    precisions, recalls = precision_recall_at_k_surprise(predictions, k=k, threshold=threshold)\n",
    "    avg_precision = np.mean(list(precisions.values()))\n",
    "    avg_recall = np.mean(list(recalls.values()))\n",
    "    return rmse, avg_precision, avg_recall, predictions\n",
    "\n",
    "# -------------------- C. Content-Based Filtering --------------------\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "    text = html.unescape(text).lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def create_book_soup(books):\n",
    "    books['Book-Title'] = books['Book-Title'].apply(clean_text)\n",
    "    books['Book-Author'] = books['Book-Author'].apply(clean_text)\n",
    "    books['Publisher'] = books['Publisher'].apply(clean_text)\n",
    "    books['soup'] = books['Book-Title'] + ' ' + (books['Book-Author'] + ' ') * 3 + books['Publisher']\n",
    "    return books\n",
    "\n",
    "def get_content_similarity(books):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(books['soup'])\n",
    "    return pairwise.cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "def recommend_content_based(title, indices, cosine_sim, books, top_n=10):\n",
    "    try:\n",
    "        idx = indices[title]\n",
    "    except KeyError:\n",
    "        return []\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n + 1]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    return books['Book-Title'].iloc[book_indices].tolist()\n",
    "\n",
    "def diversity(recommendations, indices, cosine_sim):\n",
    "    if len(recommendations) <= 1:\n",
    "        return 1.0\n",
    "    diversity_sum = 0\n",
    "    num_pairs = 0\n",
    "    for i in range(len(recommendations)):\n",
    "        for j in range(i + 1, len(recommendations)):\n",
    "            try:\n",
    "                idx_i, idx_j = indices[recommendations[i]], indices[recommendations[j]]\n",
    "                diversity_sum += (1 - cosine_sim[idx_i][idx_j])\n",
    "                num_pairs += 1\n",
    "            except KeyError:\n",
    "                continue\n",
    "    return diversity_sum / num_pairs if num_pairs else 1.0\n",
    "\n",
    "def evaluate_cbf_model(books, indices, cosine_sim, user_interactions, top_n=10):\n",
    "    precisions, recalls, diversities = [], [], []\n",
    "\n",
    "    for user, interactions in user_interactions.items():\n",
    "        actual_items = {book: 1 for book in interactions}\n",
    "        recommendations = recommend_content_based(interactions[0], indices, cosine_sim, books, top_n)\n",
    "\n",
    "        if recommendations:\n",
    "            precisions.append(precision_at_k(actual_items, recommendations, top_n))\n",
    "            recalls.append(recall_at_k(actual_items, recommendations, top_n))\n",
    "            diversities.append(diversity(recommendations, indices, cosine_sim))\n",
    "\n",
    "    print(f\"CBF Avg Precision@{top_n}: {np.mean(precisions):.4f}\")\n",
    "    print(f\"CBF Avg Recall@{top_n}: {np.mean(recalls):.4f}\")\n",
    "    print(f\"CBF Avg Diversity@{top_n}: {np.mean(diversities):.4f}\")\n",
    "\n",
    "# -------------------- D. Hybrid Recommendation System --------------------\n",
    "\n",
    "def get_book_index(book_title, books):\n",
    "    try:\n",
    "        # Get the index of the book by its title\n",
    "        return books[books['Book-Title'] == book_title].index[0]\n",
    "    except IndexError:\n",
    "        # Return -1 if the book title is not found\n",
    "        return -1\n",
    "\n",
    "def get_top_n_recommendations(user_id, ratings_df, svd_model, books_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Get the top N book recommendations for a user using a trained SVD model.\n",
    "\n",
    "    Args:\n",
    "        user_id (str or int): The ID of the user for whom to generate recommendations.\n",
    "        ratings_df (pd.DataFrame): The DataFrame containing user-book ratings.\n",
    "        svd_model (surprise.prediction_algorithms.matrix_factorization.SVD):\n",
    "            The trained SVD model from Surprise.\n",
    "        books_df (pd.DataFrame): The DataFrame containing book details, including ISBN.\n",
    "        top_n (int, optional): The number of top recommendations to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the top N recommended books\n",
    "                      with columns 'Book-Title', 'Book-Author', and 'Year-Of-Publication'.\n",
    "                      Returns an empty DataFrame if no recommendations can be made.\n",
    "    \"\"\"\n",
    "    # 1. Get the set of books the user has already rated.  We need to exclude these\n",
    "    # from the recommendations.\n",
    "    user_ratings = ratings_df[ratings_df['User-ID'] == user_id]\n",
    "    rated_book_isbns = set(user_ratings['ISBN'])\n",
    "\n",
    "    # 2. Get all unique ISBNs from the books DataFrame.  These are the books\n",
    "    # that *could* be recommended.\n",
    "    all_book_isbns = set(books_df['ISBN'])\n",
    "\n",
    "    # 3.  Find the books that the user has *not* yet rated.  These are the\n",
    "    # candidates for recommendations.\n",
    "    eligible_book_isbns = list(all_book_isbns - rated_book_isbns)\n",
    "\n",
    "    # 4. Predict ratings for the eligible books.\n",
    "    predicted_ratings = []\n",
    "    for isbn in eligible_book_isbns:\n",
    "        try:\n",
    "            # Important:  Use the string form of the user_id.\n",
    "            predicted_rating = svd_model.predict(str(user_id), isbn).est\n",
    "            predicted_ratings.append((isbn, predicted_rating))\n",
    "        except ValueError:  # Handle cases where the user or book is not in the training set\n",
    "            #  It's possible a book in books_df isn't in the training data.  Skip it.\n",
    "            print(f\"Skipping prediction for ISBN: {isbn} (Not in training data)\")\n",
    "            continue\n",
    "\n",
    "    # 5. Sort the predictions by estimated rating in descending order.\n",
    "    predicted_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 6. Get the top N ISBNs.\n",
    "    top_n_isbn_recommendations = [isbn for isbn, _ in predicted_ratings[:top_n]]\n",
    "\n",
    "    # 7.  Join with books_df to get the book details.\n",
    "    recommended_books = books_df[books_df['ISBN'].isin(top_n_isbn_recommendations)]\n",
    "\n",
    "    return recommended_books[['Book-Title', 'Book-Author', 'Year-Of-Publication']] if not recommended_books.empty else pd.DataFrame()\n",
    "\n",
    "\n",
    "def hybrid_recommendations(user_id, book_title, ratings_df, books_df, cosine_sim, svd_model, top_n=10, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Generate hybrid book recommendations for a user based on a given book title,\n",
    "    combining content-based and collaborative filtering approaches.\n",
    "\n",
    "    Args:\n",
    "        user_id (str or int): The ID of the user.\n",
    "        book_title (str): The title of the book for which to find similar books.\n",
    "        ratings_df (pd.DataFrame): DataFrame containing user-book ratings.\n",
    "        books_df (pd.DataFrame): DataFrame containing book details.\n",
    "        cosine_sim (np.ndarray): Cosine similarity matrix for books.\n",
    "        svd_model (surprise.prediction_algorithms.matrix_factorization.SVD): Trained SVD model.\n",
    "        top_n (int, optional): Number of recommendations to return. Defaults to 10.\n",
    "        alpha (float, optional): Weighting factor between content-based and collaborative\n",
    "            recommendations (0 to 1).  1.0 means use only content-based, 0.0 is only CF.\n",
    "            Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of book titles representing the hybrid recommendations.\n",
    "              Returns an empty list if the book title is not found.\n",
    "    \"\"\"\n",
    "    idx = get_book_index(book_title, books_df)  # Use the function here\n",
    "    if idx == -1:\n",
    "        print(f\"Book '{book_title}' not found in the dataset.\")\n",
    "        return []\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n + 1]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Get content-based recommendations (titles only)\n",
    "    content_recommendations_titles = books_df['Book-Title'].iloc[book_indices].tolist()\n",
    "\n",
    "    # Get collaborative filtering recommendations (Dataframe)\n",
    "    top_cf_recommendations_df = get_top_n_recommendations(\n",
    "        user_id, ratings_df, svd_model, books_df, top_n\n",
    "    )\n",
    "    top_cf_recommendations_titles = top_cf_recommendations_df['Book-Title'].tolist()\n",
    "\n",
    "    # Combine recommendations, handling potential duplicates, and limit to top_n\n",
    "    hybrid_recommendations_titles = []\n",
    "    content_weight = alpha\n",
    "    cf_weight = 1 - alpha\n",
    "\n",
    "    # Add content-based recommendations, weighted\n",
    "    for title in content_recommendations_titles:\n",
    "        if title not in hybrid_recommendations_titles:\n",
    "            hybrid_recommendations_titles.append(title)\n",
    "        if len(hybrid_recommendations_titles) >= top_n:\n",
    "            break\n",
    "\n",
    "    # Add collaborative filtering recommendations, weighted\n",
    "    for title in top_cf_recommendations_titles:\n",
    "        if title not in hybrid_recommendations_titles:\n",
    "            hybrid_recommendations_titles.append(title)\n",
    "        if len(hybrid_recommendations_titles) >= top_n:\n",
    "            break\n",
    "    return hybrid_recommendations_titles\n",
    "# -------------------- E. Main Program --------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load datasets\n",
    "    ratings = pd.read_csv(\"ratings_cleaned.csv\")\n",
    "    books = pd.read_csv(\"books_cleaned.csv\").head(5000)\n",
    "\n",
    "    # --- Collaborative Filtering ---\n",
    "    print(\"\\n--- Collaborative Filtering ---\")\n",
    "    data, trainset, testset = load_and_prepare_cf_data()\n",
    "    algo = train_svd_model(trainset)\n",
    "    rmse, precision, recall, _ = evaluate_cf_model(algo, testset)\n",
    "    print(f\"CF RMSE: {rmse:.4f}\")\n",
    "    print(f\"CF Avg Precision@10: {precision:.4f}\")\n",
    "    print(f\"CF Avg Recall@10: {recall:.4f}\")\n",
    "\n",
    "    # --- Content-Based Filtering ---\n",
    "    print(\"\\n--- Content-Based Filtering ---\")\n",
    "    books = create_book_soup(books)\n",
    "    cosine_sim = get_content_similarity(books)\n",
    "    indices = pd.Series(books.index, index=books['Book-Title']).to_dict()\n",
    "\n",
    "    # Dummy user interactions (simulate a few users)\n",
    "    user_interactions = {\n",
    "        'User1': [books['Book-Title'].iloc[10], books['Book-Title'].iloc[20]],\n",
    "        'User2': [books['Book-Title'].iloc[5], books['Book-Title'].iloc[15]],\n",
    "        'User3': [books['Book-Title'].iloc[3], books['Book-Title'].iloc[25]]\n",
    "    }\n",
    "\n",
    "    evaluate_cbf_model(books, indices, cosine_sim, user_interactions)\n",
    "\n",
    "    # --- Hybrid Recommendation ---\n",
    "    print(\"\\n--- Hybrid Recommendation ---\")\n",
    "    # Assuming '276725' is a valid user ID from your ratings data\n",
    "    hybrid_recs = hybrid_recommendations(\n",
    "        user_id='276725',\n",
    "        book_title='black water',\n",
    "        ratings_df=ratings,  # Pass the ratings DataFrame\n",
    "        books_df=books,\n",
    "        cosine_sim=cosine_sim,\n",
    "        svd_model=algo,\n",
    "        top_n=10,\n",
    "        alpha=0.6  # Adjust alpha as needed (0.6 favors content-based slightly)\n",
    "    )\n",
    "    if hybrid_recs:\n",
    "        print(f\"Hybrid recommendations for user 276725 based on 'black water':\")\n",
    "        for title in hybrid_recs:\n",
    "            print(f\"- {title}\")\n",
    "    else:\n",
    "        print(\"No hybrid recommendations found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15ae7d-6ef0-4dd8-9afb-1975907a5f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
